{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Getting started \u00b6 Daisi (app.daisi.io) is a scientific Cloud Computing platform running Python serverless functions, named Daisies . With Daisi you can: create web services, automate tasks, host apps\u2026 orders of magnitude easier and faster than traditional cloud platforms. parallelize compute intensive workloads by scaling up instantly to thousands of processes on demand. share your code and discover thousands of ready-to-call functions and apps ! Daisi brings the power of cloud computing into the hands of every developer, scientist, engineer by automatically deploying and creating endpoints for any function of a Python code, which can then be invoked seamlessly from any environment. Any regular Python code can be turned into a Daisi by simply registering its Github repository in the Daisi platform, with no need to write any specific code . Note This project is under active development Quick start with the pydaisi Python package \u00b6 Calling \"Hello World !\" \u00b6 Install pydaisi ( requires Python 3.8+ ) pip install -- upgrade pydaisi Call the \"Print Hello\" Daisi and invoke the hello() endpoint import pydaisi as pyd greeting_daisi = pyd . Daisi ( \"exampledaisies/Print Hello\" ) greeting_daisi . hello ( name = \"Daisi user\" ) . value Check the code of this Daisi on app.daisi.io: \"Print Hello\" . And browse app.daisi.io to more discover Daisies ! What just happened ? Cloud Computing made easy ! \u00b6 We have instantiated a Daisi object and passed the name of a serverless function from the Daisi platform in argument. This is how you can call any available Daisi. The pattern to call a Daisi is \"username/daisiname\" , except if the Daisi is public and its name is unique, in which case you can ommit \"username\" . A Daisi can have multiple endpoints. Endpoints are created automatically for every fuction in the main script of your code. They are simply invoked as a method of the Daisi object, with the method name being the name of the function. In this example, we have invoked the hello endpoint of the Print Hello Daisi. With pydaisi you can send and receive arbitrary Python objects, as if you were passing arguments to a local function. No need to serialize / deserialize, pydaisi handles it automatically. Invoking a Daisi endpoint returns a DaisiExecution object. The value returned can be simply retrieved by querying its . value attribute. Note Public Daisies can be called without being authentified. Private Daisies shared within a team require authentication (see the Authentication section) Daisies can also be apps ! \u00b6 You can give a nice front end to your Daisies, and the platform currently supports Streamlit (more frameworks to come). And convert your Daisi into a fully deployed app with an API for computer access.... Check this Daisi: \"Print Hello App\"","title":"Getting started"},{"location":"#getting-started","text":"Daisi (app.daisi.io) is a scientific Cloud Computing platform running Python serverless functions, named Daisies . With Daisi you can: create web services, automate tasks, host apps\u2026 orders of magnitude easier and faster than traditional cloud platforms. parallelize compute intensive workloads by scaling up instantly to thousands of processes on demand. share your code and discover thousands of ready-to-call functions and apps ! Daisi brings the power of cloud computing into the hands of every developer, scientist, engineer by automatically deploying and creating endpoints for any function of a Python code, which can then be invoked seamlessly from any environment. Any regular Python code can be turned into a Daisi by simply registering its Github repository in the Daisi platform, with no need to write any specific code . Note This project is under active development","title":"Getting started"},{"location":"#quick-start-with-the-pydaisi-python-package","text":"","title":"Quick start with the pydaisi Python package"},{"location":"#calling-hello-world","text":"Install pydaisi ( requires Python 3.8+ ) pip install -- upgrade pydaisi Call the \"Print Hello\" Daisi and invoke the hello() endpoint import pydaisi as pyd greeting_daisi = pyd . Daisi ( \"exampledaisies/Print Hello\" ) greeting_daisi . hello ( name = \"Daisi user\" ) . value Check the code of this Daisi on app.daisi.io: \"Print Hello\" . And browse app.daisi.io to more discover Daisies !","title":"Calling \"Hello World !\""},{"location":"#what-just-happened-cloud-computing-made-easy","text":"We have instantiated a Daisi object and passed the name of a serverless function from the Daisi platform in argument. This is how you can call any available Daisi. The pattern to call a Daisi is \"username/daisiname\" , except if the Daisi is public and its name is unique, in which case you can ommit \"username\" . A Daisi can have multiple endpoints. Endpoints are created automatically for every fuction in the main script of your code. They are simply invoked as a method of the Daisi object, with the method name being the name of the function. In this example, we have invoked the hello endpoint of the Print Hello Daisi. With pydaisi you can send and receive arbitrary Python objects, as if you were passing arguments to a local function. No need to serialize / deserialize, pydaisi handles it automatically. Invoking a Daisi endpoint returns a DaisiExecution object. The value returned can be simply retrieved by querying its . value attribute. Note Public Daisies can be called without being authentified. Private Daisies shared within a team require authentication (see the Authentication section)","title":"What just happened ? Cloud Computing made easy !"},{"location":"#daisies-can-also-be-apps","text":"You can give a nice front end to your Daisies, and the platform currently supports Streamlit (more frameworks to come). And convert your Daisi into a fully deployed app with an API for computer access.... Check this Daisi: \"Print Hello App\"","title":"Daisies can also be apps !"},{"location":"0.1.create-daisi/","text":"Create a Daisi \u00b6 A Daisi can be created from any Python code which is stored on Github. So the first step is to make sure that your code is actually pushed to a Github repository. You need to have an account and to be logged in the Daisi platform app.daisi.io to create a new Daisi. Sign up to create an account or sign in. From Python code to a deployed serveless function in one click \u00b6 Let's start by creating a simple Print Hello daisi. The Python code would simply be a regular Python function: def hello ( name = \"World\" ): return \"Hello \" + str ( name ) Turning this code into a deployed serverless function only requires two steps: Step 1 : Push the code to a Github repository. Step 2 : Register the Github repository in the Daisi platform. Click on the Create a new daisi button, give the daisi a name ( Print Hello for instance) and enter the address to the Github repository. On the next screen, confirm the branch to use, the folder in the repository and the Python script containing the function. Then click on Create . The Daisi platform will automatically parse the requirements, create a virtual environment and generate an endpoint for every function in the code. When it says \"Ready\", your code is now deployed and a worker will be available to run it whenever someone triggers its execution ! Open the card corresponding to the new Print Hello daisi and go to the How to tab. Our code contains simply one function ( def hello() ), so only one endpoint has been created ( hello ). In case that multiple functions are present in the main script, there will be one endpoint per function. Print Hello can be called from various clients, including with a regular HTTP request (see the CURL tab). At the moment, the Python client pyDaisi is the most developed. The Python section of the How to tab features a snippet of code to call immediately the Daisi from a remote environment with pydaisi (see Simple executions ). In this example, it should look like: import pydaisi as pyd print_hello = pyd . Daisi ( username / \"Print Hello\" ) Go to Settings and click on the Make public button. Your \"Print Hello\" Daisi is now visible by every Daisi user, they can open its card and call it with pydaisi . Visibility settings are describe in Sharing Daisies - Teams Virtual environment creation \u00b6 A virtual environment will be automatically created for your Daisi to run. The venv will be populated with the required Python packages and dependencies. The Daisi platform will create the virtual environment with Miniconda and then uses pip to install and manage Python packages. If no requirements.txt file is available in the folder of the main script, the Daisi platform will parse the main script and try to identify the required packages. However, it is strongly recommended to include a requirements.txt file, and to specify the version number of the packages if needed. You can generate a requirements file with pip freeze > requirements.txt Endpoints creation \u00b6 Endpoints will be created for every function of the Python script that you have selected, i.e for every def statement: # An endpoint will be created automatically for my_func() def my_func ( * args ): # do and return something With the following exceptions: There is no function definition : if your code is simply a series of statements, without any function definition, the Daisi platform will not create any endpoint. No endpoints will be created for classes definition No endpoints will be created for classes methods No endpoints will be created for module privates (whith name starting with an _ or __ ) Think about how you want to design your endpoints and write functions accordingly so they deliver the most value to your end users. Endpoints documentation \u00b6 A documentation is generated automatically for each endpoint created. It is strongly recommended to add docstrings to document the functions which will be the most important endpoints of your Daisi, describing the input arguments and the returned objects. We encourage to follow the format below: def my_func ( name1 , name2 ) # Here below is the docstring: ''' A short sentence describing the function purpose Parameters: - name1 (type) : description - name2 (type) : description Return: - object type : description ''' Adding a Readme ( DAISI.md ) \u00b6 The Readme tab of the daisi page will display the content of the DAISI.md from your Github repository. It will try to default to README.md if DAISI.md is not present. It is a good practice to include a DAISI.md file which explains what your Daisi does, and write a self-contained example that a user could copy to have an immediate overview of how your Daisi works. Include also any useful reference to the code, including source papers, and give appropriate credits. Check the Examples section in the Daisi platform for examples of DAISI.md . Updating the metadata \u00b6 In the Settings tab, you can add the following information to make your Daisi easily discoverable in the platform: tags: you can type in any relevant tag for your Daisi. Try to reuse existing tags as much as possible to aboid duplicate and make it easily discoverable image : add an inspiring image which will be featured on the Daisi card, so it get noticed description : a short sentence describing your Daisi which will be featured in the Daisi card. It is not supposed to replace the content of the DAISI.md file. Keep detailed descriptions for the Readme tab.","title":"Create a Daisi"},{"location":"0.1.create-daisi/#create-a-daisi","text":"A Daisi can be created from any Python code which is stored on Github. So the first step is to make sure that your code is actually pushed to a Github repository. You need to have an account and to be logged in the Daisi platform app.daisi.io to create a new Daisi. Sign up to create an account or sign in.","title":"Create a Daisi"},{"location":"0.1.create-daisi/#from-python-code-to-a-deployed-serveless-function-in-one-click","text":"Let's start by creating a simple Print Hello daisi. The Python code would simply be a regular Python function: def hello ( name = \"World\" ): return \"Hello \" + str ( name ) Turning this code into a deployed serverless function only requires two steps: Step 1 : Push the code to a Github repository. Step 2 : Register the Github repository in the Daisi platform. Click on the Create a new daisi button, give the daisi a name ( Print Hello for instance) and enter the address to the Github repository. On the next screen, confirm the branch to use, the folder in the repository and the Python script containing the function. Then click on Create . The Daisi platform will automatically parse the requirements, create a virtual environment and generate an endpoint for every function in the code. When it says \"Ready\", your code is now deployed and a worker will be available to run it whenever someone triggers its execution ! Open the card corresponding to the new Print Hello daisi and go to the How to tab. Our code contains simply one function ( def hello() ), so only one endpoint has been created ( hello ). In case that multiple functions are present in the main script, there will be one endpoint per function. Print Hello can be called from various clients, including with a regular HTTP request (see the CURL tab). At the moment, the Python client pyDaisi is the most developed. The Python section of the How to tab features a snippet of code to call immediately the Daisi from a remote environment with pydaisi (see Simple executions ). In this example, it should look like: import pydaisi as pyd print_hello = pyd . Daisi ( username / \"Print Hello\" ) Go to Settings and click on the Make public button. Your \"Print Hello\" Daisi is now visible by every Daisi user, they can open its card and call it with pydaisi . Visibility settings are describe in Sharing Daisies - Teams","title":"From Python code to a deployed serveless function in one click"},{"location":"0.1.create-daisi/#virtual-environment-creation","text":"A virtual environment will be automatically created for your Daisi to run. The venv will be populated with the required Python packages and dependencies. The Daisi platform will create the virtual environment with Miniconda and then uses pip to install and manage Python packages. If no requirements.txt file is available in the folder of the main script, the Daisi platform will parse the main script and try to identify the required packages. However, it is strongly recommended to include a requirements.txt file, and to specify the version number of the packages if needed. You can generate a requirements file with pip freeze > requirements.txt","title":"Virtual environment creation"},{"location":"0.1.create-daisi/#endpoints-creation","text":"Endpoints will be created for every function of the Python script that you have selected, i.e for every def statement: # An endpoint will be created automatically for my_func() def my_func ( * args ): # do and return something With the following exceptions: There is no function definition : if your code is simply a series of statements, without any function definition, the Daisi platform will not create any endpoint. No endpoints will be created for classes definition No endpoints will be created for classes methods No endpoints will be created for module privates (whith name starting with an _ or __ ) Think about how you want to design your endpoints and write functions accordingly so they deliver the most value to your end users.","title":"Endpoints creation"},{"location":"0.1.create-daisi/#endpoints-documentation","text":"A documentation is generated automatically for each endpoint created. It is strongly recommended to add docstrings to document the functions which will be the most important endpoints of your Daisi, describing the input arguments and the returned objects. We encourage to follow the format below: def my_func ( name1 , name2 ) # Here below is the docstring: ''' A short sentence describing the function purpose Parameters: - name1 (type) : description - name2 (type) : description Return: - object type : description '''","title":"Endpoints documentation"},{"location":"0.1.create-daisi/#adding-a-readme-daisimd","text":"The Readme tab of the daisi page will display the content of the DAISI.md from your Github repository. It will try to default to README.md if DAISI.md is not present. It is a good practice to include a DAISI.md file which explains what your Daisi does, and write a self-contained example that a user could copy to have an immediate overview of how your Daisi works. Include also any useful reference to the code, including source papers, and give appropriate credits. Check the Examples section in the Daisi platform for examples of DAISI.md .","title":"Adding a Readme (DAISI.md)"},{"location":"0.1.create-daisi/#updating-the-metadata","text":"In the Settings tab, you can add the following information to make your Daisi easily discoverable in the platform: tags: you can type in any relevant tag for your Daisi. Try to reuse existing tags as much as possible to aboid duplicate and make it easily discoverable image : add an inspiring image which will be featured on the Daisi card, so it get noticed description : a short sentence describing your Daisi which will be featured in the Daisi card. It is not supposed to replace the content of the DAISI.md file. Keep detailed descriptions for the Readme tab.","title":"Updating the metadata"},{"location":"0.2.update-daisi/","text":"Update a Daisi \u00b6 When a new version of your code is available to Github, you can push it to the Daisi platform: Open the Settings tab in your Daisi page Click on Synchronise . You will be asked to select the branch with which to make the update. Update when the requirements have changed \u00b6 In the current version of the Daisi Platform, you will need to delete your Daisi and recreate it if the requirements have changed (new version of requirements.txt ). Streamlit apps update \u00b6 When you push a new version of your code which can render a Streamlit app, the app should be immediately updated. Just close any browser window where the app is rendered and re-click on Launch the app in the Daisi page.","title":"Update a Daisi"},{"location":"0.2.update-daisi/#update-a-daisi","text":"When a new version of your code is available to Github, you can push it to the Daisi platform: Open the Settings tab in your Daisi page Click on Synchronise . You will be asked to select the branch with which to make the update.","title":"Update a Daisi"},{"location":"0.2.update-daisi/#update-when-the-requirements-have-changed","text":"In the current version of the Daisi Platform, you will need to delete your Daisi and recreate it if the requirements have changed (new version of requirements.txt ).","title":"Update when the requirements have changed"},{"location":"0.2.update-daisi/#streamlit-apps-update","text":"When you push a new version of your code which can render a Streamlit app, the app should be immediately updated. Just close any browser window where the app is rendered and re-click on Launch the app in the Daisi page.","title":"Streamlit apps update"},{"location":"1.authentication/","text":"Authentication \u00b6 An access token is required to execute private daisies on app.daisi.io . Private Daisies are any Daisies which have not been made \"Public\". They can be Daisies that you own and visible only to you or Daisies which have been shared within a team you belong to. Getting an access token \u00b6 Once you are logged on the platform : click on your account settings (top right) and select Personal Access Tokens click on Generate a New Token and fill in the form (name, expiration date) copy the token and store it in a secret file Note This is the only time this token will be visible in the platform. The Daisi plateform doesn't store your tokens. You can have multiple tokens. The Personal Access Tokens page allows to manage them. Authentication \u00b6 iPython / Jupyter notebook \u00b6 In an iPython console or a Jupyter notebook, set the DAISI_ACCESS_TOKEN environment variable as follow: import os os . environ [ \"DAISI_ACCESS_TOKEN\" ] =< your access token > Using a shell environment variable \u00b6 Define a DAISI_ACCESS_TOKEN environment variable. In a sh type shell (sh, bash, ksh, zsh, ...): export DAISI_ACCESS_TOKEN = <your access token> In a csh type shell (csh, tcsh, ...): setenv DAISI_ACCESS_TOKEN <your access token> Using an .env file \u00b6 Add the following line in a .env file: DAISI_ACCESS_TOKEN = <your access token> Then source .env","title":"Authentication"},{"location":"1.authentication/#authentication","text":"An access token is required to execute private daisies on app.daisi.io . Private Daisies are any Daisies which have not been made \"Public\". They can be Daisies that you own and visible only to you or Daisies which have been shared within a team you belong to.","title":"Authentication"},{"location":"1.authentication/#getting-an-access-token","text":"Once you are logged on the platform : click on your account settings (top right) and select Personal Access Tokens click on Generate a New Token and fill in the form (name, expiration date) copy the token and store it in a secret file Note This is the only time this token will be visible in the platform. The Daisi plateform doesn't store your tokens. You can have multiple tokens. The Personal Access Tokens page allows to manage them.","title":"Getting an access token"},{"location":"1.authentication/#authentication_1","text":"","title":"Authentication"},{"location":"1.authentication/#ipython-jupyter-notebook","text":"In an iPython console or a Jupyter notebook, set the DAISI_ACCESS_TOKEN environment variable as follow: import os os . environ [ \"DAISI_ACCESS_TOKEN\" ] =< your access token >","title":"iPython / Jupyter notebook"},{"location":"1.authentication/#using-a-shell-environment-variable","text":"Define a DAISI_ACCESS_TOKEN environment variable. In a sh type shell (sh, bash, ksh, zsh, ...): export DAISI_ACCESS_TOKEN = <your access token> In a csh type shell (csh, tcsh, ...): setenv DAISI_ACCESS_TOKEN <your access token>","title":"Using a shell environment variable"},{"location":"1.authentication/#using-an-env-file","text":"Add the following line in a .env file: DAISI_ACCESS_TOKEN = <your access token> Then source .env","title":"Using an .env file"},{"location":"2.pydaisi_part1/","text":"Simple executions \u00b6 Calling a Daisi \u00b6 The pattern to call a Daisi is Daisi ( \"username/daisiname\" ) , except if the Daisi is public and its name is unique, in which case you can ommit \"username\" . The Call it tab in each Daisi page on app.daisi.io features a snippet of code that you can copy/paste to call a Daisi immediately (Pending that you are authentified. Only public Daisies don't require authentication). Simple invokations \u00b6 Synchronous calls \u00b6 You can invoke a Daisi endpoint, it will run until complete, and the result will be available in the value attribute when it has returned. import pydaisi as pyd # Instantiate a Daisi object classify = pyd . Daisi ( \"Zero Shot Text Classification\" ) # Synchronous call result = classify . compute ( text = \"Let's go the moon\" , candidate_labels = \"astronomy, travel\" ) . value Execution Status \u00b6 A Daisi's execution status can be accessed with the status property: with pyd . Daisi ( \"Add Two Numbers\" ) as my_daisi : de = my_daisi . compute ( firstNumber = 5 , secondNumber = 6 ) print ( de . status ) Status is one of the following: NOT STARTED RUNNING FINISHED FAILED When the execution status value is FINISHED , you can fetch the result: result = de . value print ( result ) Execution Logs \u00b6 A Daisi's logs can be accessed with the logs property: import time with pyd . Daisi ( \"Live Logging\" ) as my_daisi : de = my_daisi . live_log_test ( firstNumber = 5 , secondNumber = 6 , delay = 3 ) de . start () time . sleep ( 2 ) print ( de . logs ) Tracebacks \u00b6 When your code fails and produce a traceback, it will be reported in the .value attribute. Passing and receiving arbitrary objects \u00b6 Daisies can be passed and send back arbitrary Python objects, as if they were simply functions in a Python module. There is nothing special to do to pass arguments to a Daisi. However, as for any Python module, if you pass custom objects, their definition needs to be available to the Daisi. Consider this example with \"Daisi Serialize\" : The code of \"Daisi Serialize\" Daisi is the following : import numpy as np # A class definition. No endpoints are created for the methods of the class class Stack : def __init__ ( self , nx ): self . stack = np . zeros (( 1 , nx )) self . nb_layers = self . stack . shape [ 0 ] def stack_arrays ( self , array ): self . stack += 1 self . stack = np . vstack (( self . stack , array )) self . nb_layers = self . stack . shape [ 0 ] # A function, for which an endpoint is created def compute ( stack , array ): return stack . stack_arrays ( array ) The compute function of this Daisi receives and returns a Stack object. The code below illustrates how we can interact with this Daisi : Instantiate a Stack object Pass it to the Daisi Receive a new Stack object import pydaisi as pyd import numpy as np # Connect to the \"Daisi Serialize\" Daisi daisi_serialize = pyd . Daisi ( \"exampledaisies/Daisi Serialize\" ) # Class definition class Stack : def __init__ ( self , nx ): self . stack = np . zeros (( 1 , nx )) self . nb_layers = self . stack . shape [ 0 ] def stack_arrays ( self , array ): self . stack += 1 self . stack = np . vstack (( self . stack , array )) self . nb_layers = self . stack . shape [ 0 ] # Initialize a new GridStack object with 10 layers nx = 100 s = Stack ( nx ) for i in range ( 8 ): s . stack_arrays ( np . random . rand ( nx ,)) # Invoke the \"compute()\" endpoint, add a new layer to the stack # and receive back the updated Stack object d_execution = daisi_serialize . compute ( stack = s , array = np . random . rand ( nx ,)) . value assert d_execution . nb_layers == 10 Asynchronous calls and long running executions \u00b6 The Daisi plateform supports long running executions. To trigger a long running execution, invoke the endpoint asynchronously. The DaisiExecution object will return immediately an execution_id . You will monitor the execution progress with the .status and .logs properties. To call an endpoint asynchronously, simply add a _ suffix at the end of the endpoint name. Example: greeting = pyd . Daisi ( \"Print Hello\" ) async_exec = greeting . hello_ ( name = \"World\" ) # Note the \"_\" character after \"hello\" print ( async_exec . status ) # Then fetch the `DaisiExecution` result with the `.value` attribute when ready print ( async_exec . value ) Remote Results \u00b6 You need not fetch the full data of a Daisi Execution in order to chain it to the computation of another daisi ! Consider this example with \"Daisi Serialize\" : import pydaisi as pyd # Connect to the \"Daisi Serialize\" Daisi d = pyd . Daisi ( \"Daisi Serialize\" ) # Define the GridStack class that we will # use as an example of custom serialization. A GridStack # object will be passed in argument of the Daisi. # The \"Daisi Serialize\" Daisi contains also # a definition of the class. import numpy as np class GridStack : def __init__ ( self , nx , ny ): self . nx = nx self . ny = ny self . nb_layers = None self . grids = [] def add_layer ( self , grid ): if grid . shape == ( self . ny , self . nx ): self . maps . append ( grid ) self . nb_layers = len ( self . grids ) return \"Map sucessfully added.\" else : return \"Could not add map. Incompatible dimensions.\" # Initialize a new GridStack object with 10 layers gs = GridStack ( nx = 200 , ny = 200 ) for i in range ( 10 ): ms . add_layer ( np . random . rand ( nx , ny )) # Invoke the daisi endpoint asynchronously, adding a new layer to the grid stack d_execution = d . compute_ ( grid_stack = ms , grid = np . random . rand ( nx , ny )) The DaisiExecution object d_execution contains simply a reference to the remote result unless it is explicitely fetched. There is no need to fetch the result in order to pass it as an input to the next daisi ! # Recompute the daisi, adding a another new layer and fetch the result result = d . compute_ ( grid_stack = d_execution , grid = np . random . rand ( nx , ny )) . value assert result . nb_layers == 12 Map parallel executions \u00b6","title":"Simple executions"},{"location":"2.pydaisi_part1/#simple-executions","text":"","title":"Simple executions"},{"location":"2.pydaisi_part1/#calling-a-daisi","text":"The pattern to call a Daisi is Daisi ( \"username/daisiname\" ) , except if the Daisi is public and its name is unique, in which case you can ommit \"username\" . The Call it tab in each Daisi page on app.daisi.io features a snippet of code that you can copy/paste to call a Daisi immediately (Pending that you are authentified. Only public Daisies don't require authentication).","title":"Calling a Daisi"},{"location":"2.pydaisi_part1/#simple-invokations","text":"","title":"Simple invokations"},{"location":"2.pydaisi_part1/#synchronous-calls","text":"You can invoke a Daisi endpoint, it will run until complete, and the result will be available in the value attribute when it has returned. import pydaisi as pyd # Instantiate a Daisi object classify = pyd . Daisi ( \"Zero Shot Text Classification\" ) # Synchronous call result = classify . compute ( text = \"Let's go the moon\" , candidate_labels = \"astronomy, travel\" ) . value","title":"Synchronous calls"},{"location":"2.pydaisi_part1/#execution-status","text":"A Daisi's execution status can be accessed with the status property: with pyd . Daisi ( \"Add Two Numbers\" ) as my_daisi : de = my_daisi . compute ( firstNumber = 5 , secondNumber = 6 ) print ( de . status ) Status is one of the following: NOT STARTED RUNNING FINISHED FAILED When the execution status value is FINISHED , you can fetch the result: result = de . value print ( result )","title":"Execution Status"},{"location":"2.pydaisi_part1/#execution-logs","text":"A Daisi's logs can be accessed with the logs property: import time with pyd . Daisi ( \"Live Logging\" ) as my_daisi : de = my_daisi . live_log_test ( firstNumber = 5 , secondNumber = 6 , delay = 3 ) de . start () time . sleep ( 2 ) print ( de . logs )","title":"Execution Logs"},{"location":"2.pydaisi_part1/#tracebacks","text":"When your code fails and produce a traceback, it will be reported in the .value attribute.","title":"Tracebacks"},{"location":"2.pydaisi_part1/#passing-and-receiving-arbitrary-objects","text":"Daisies can be passed and send back arbitrary Python objects, as if they were simply functions in a Python module. There is nothing special to do to pass arguments to a Daisi. However, as for any Python module, if you pass custom objects, their definition needs to be available to the Daisi. Consider this example with \"Daisi Serialize\" : The code of \"Daisi Serialize\" Daisi is the following : import numpy as np # A class definition. No endpoints are created for the methods of the class class Stack : def __init__ ( self , nx ): self . stack = np . zeros (( 1 , nx )) self . nb_layers = self . stack . shape [ 0 ] def stack_arrays ( self , array ): self . stack += 1 self . stack = np . vstack (( self . stack , array )) self . nb_layers = self . stack . shape [ 0 ] # A function, for which an endpoint is created def compute ( stack , array ): return stack . stack_arrays ( array ) The compute function of this Daisi receives and returns a Stack object. The code below illustrates how we can interact with this Daisi : Instantiate a Stack object Pass it to the Daisi Receive a new Stack object import pydaisi as pyd import numpy as np # Connect to the \"Daisi Serialize\" Daisi daisi_serialize = pyd . Daisi ( \"exampledaisies/Daisi Serialize\" ) # Class definition class Stack : def __init__ ( self , nx ): self . stack = np . zeros (( 1 , nx )) self . nb_layers = self . stack . shape [ 0 ] def stack_arrays ( self , array ): self . stack += 1 self . stack = np . vstack (( self . stack , array )) self . nb_layers = self . stack . shape [ 0 ] # Initialize a new GridStack object with 10 layers nx = 100 s = Stack ( nx ) for i in range ( 8 ): s . stack_arrays ( np . random . rand ( nx ,)) # Invoke the \"compute()\" endpoint, add a new layer to the stack # and receive back the updated Stack object d_execution = daisi_serialize . compute ( stack = s , array = np . random . rand ( nx ,)) . value assert d_execution . nb_layers == 10","title":"Passing and receiving arbitrary objects"},{"location":"2.pydaisi_part1/#asynchronous-calls-and-long-running-executions","text":"The Daisi plateform supports long running executions. To trigger a long running execution, invoke the endpoint asynchronously. The DaisiExecution object will return immediately an execution_id . You will monitor the execution progress with the .status and .logs properties. To call an endpoint asynchronously, simply add a _ suffix at the end of the endpoint name. Example: greeting = pyd . Daisi ( \"Print Hello\" ) async_exec = greeting . hello_ ( name = \"World\" ) # Note the \"_\" character after \"hello\" print ( async_exec . status ) # Then fetch the `DaisiExecution` result with the `.value` attribute when ready print ( async_exec . value )","title":"Asynchronous calls and long running executions"},{"location":"2.pydaisi_part1/#remote-results","text":"You need not fetch the full data of a Daisi Execution in order to chain it to the computation of another daisi ! Consider this example with \"Daisi Serialize\" : import pydaisi as pyd # Connect to the \"Daisi Serialize\" Daisi d = pyd . Daisi ( \"Daisi Serialize\" ) # Define the GridStack class that we will # use as an example of custom serialization. A GridStack # object will be passed in argument of the Daisi. # The \"Daisi Serialize\" Daisi contains also # a definition of the class. import numpy as np class GridStack : def __init__ ( self , nx , ny ): self . nx = nx self . ny = ny self . nb_layers = None self . grids = [] def add_layer ( self , grid ): if grid . shape == ( self . ny , self . nx ): self . maps . append ( grid ) self . nb_layers = len ( self . grids ) return \"Map sucessfully added.\" else : return \"Could not add map. Incompatible dimensions.\" # Initialize a new GridStack object with 10 layers gs = GridStack ( nx = 200 , ny = 200 ) for i in range ( 10 ): ms . add_layer ( np . random . rand ( nx , ny )) # Invoke the daisi endpoint asynchronously, adding a new layer to the grid stack d_execution = d . compute_ ( grid_stack = ms , grid = np . random . rand ( nx , ny )) The DaisiExecution object d_execution contains simply a reference to the remote result unless it is explicitely fetched. There is no need to fetch the result in order to pass it as an input to the next daisi ! # Recompute the daisi, adding a another new layer and fetch the result result = d . compute_ ( grid_stack = d_execution , grid = np . random . rand ( nx , ny )) . value assert result . nb_layers == 12","title":"Remote Results"},{"location":"2.pydaisi_part1/#map-parallel-executions","text":"","title":"Map parallel executions"},{"location":"2.pydaisi_part2/","text":"Parallel executions \u00b6 The Daisi platform supports parallel executions, meaning that multiple workers can be assigned to a Daisi. pydaisi currently supports a straightforward Map and monolithic reduce framework, hence making it easy to address embarrassingly parallel problems. Warning This feature is an alpha version and has currently many limitations. Set and monitor workers \u00b6 By default, every Daisi is assigned 1 worker. daisi.workers.set will set the number of workers to the specified value, i.e. if the available worker is too many, it will delete the extra workers, vice versa. Warning This setting is for the Daisi, meaning that it will affect all users. import pydaisi as pyd daisi = pyd . Daisi ( 'exampledaisies/Add Two Numbers' ) # before set workers print ( daisi . workers . number ) # asynchronous call worker_number = 50 daisi . workers . set ( worker_number ) # after set workers, it will take a while to delete or create workers print ( daisi . workers . number ) # check the status of the workers update, i.e. # increasing, decreasing, ready_to_update print ( daisi . workers . status ) Running a Daisi in parallel \u00b6 In a map framework, the same function will be applied to each input. pydaisi allows to pass a list of inputs as an argument of a Daisi, using the map method: import pydaisi as pyd with pyd . Daisi ( \"Add Two Numbers\" ) as my_daisi : dbe = my_daisi . map ( func = \"compute\" , args_list = [{ \"firstNumber\" : 5 , \"secondNumber\" : x } for x in range ( 10 )]) print ( dbe . value ) A more realistic example \u00b6 Consider the example below which combines two Daisies: A Daisi to fetch news from Google News A Daisi to analyze the sentiment of each title Running one execution of the Sentiment Analysis Daisi has a wall time of about 700ms. If we query 100 news results, thats about 70s of computation. By distributing this task on 4 workers, we can get it done in about 10s. import pydaisi as pyd import pandas as pd google_news = pyd . Daisi ( \"exampledaisies/GoogleNews\" ) # the \"GoogleNews\" Daisi returns a Pandas Dataframe. # We will put the titles in a list. news_title = google_news . get_news ( query = \"Apple\" , nb = 100 ) . value [ 'title' ] . to_list () classify = pyd . Daisi ( \"exampledaisies/Zero Shot Text Classification\" ) # Prepare a parallel execution dbe = classify . map ( func = \"compute\" , args_list = [{ \"text\" : title , \"candidate_labels\" : \"positive, negative\" } for title in news_title ]) dbe . start () # Wait for completion while \"RUNNING\" in dbe . value :","title":"Parallel executions"},{"location":"2.pydaisi_part2/#parallel-executions","text":"The Daisi platform supports parallel executions, meaning that multiple workers can be assigned to a Daisi. pydaisi currently supports a straightforward Map and monolithic reduce framework, hence making it easy to address embarrassingly parallel problems. Warning This feature is an alpha version and has currently many limitations.","title":"Parallel executions"},{"location":"2.pydaisi_part2/#set-and-monitor-workers","text":"By default, every Daisi is assigned 1 worker. daisi.workers.set will set the number of workers to the specified value, i.e. if the available worker is too many, it will delete the extra workers, vice versa. Warning This setting is for the Daisi, meaning that it will affect all users. import pydaisi as pyd daisi = pyd . Daisi ( 'exampledaisies/Add Two Numbers' ) # before set workers print ( daisi . workers . number ) # asynchronous call worker_number = 50 daisi . workers . set ( worker_number ) # after set workers, it will take a while to delete or create workers print ( daisi . workers . number ) # check the status of the workers update, i.e. # increasing, decreasing, ready_to_update print ( daisi . workers . status )","title":"Set and monitor workers"},{"location":"2.pydaisi_part2/#running-a-daisi-in-parallel","text":"In a map framework, the same function will be applied to each input. pydaisi allows to pass a list of inputs as an argument of a Daisi, using the map method: import pydaisi as pyd with pyd . Daisi ( \"Add Two Numbers\" ) as my_daisi : dbe = my_daisi . map ( func = \"compute\" , args_list = [{ \"firstNumber\" : 5 , \"secondNumber\" : x } for x in range ( 10 )]) print ( dbe . value )","title":"Running a Daisi in parallel"},{"location":"2.pydaisi_part2/#a-more-realistic-example","text":"Consider the example below which combines two Daisies: A Daisi to fetch news from Google News A Daisi to analyze the sentiment of each title Running one execution of the Sentiment Analysis Daisi has a wall time of about 700ms. If we query 100 news results, thats about 70s of computation. By distributing this task on 4 workers, we can get it done in about 10s. import pydaisi as pyd import pandas as pd google_news = pyd . Daisi ( \"exampledaisies/GoogleNews\" ) # the \"GoogleNews\" Daisi returns a Pandas Dataframe. # We will put the titles in a list. news_title = google_news . get_news ( query = \"Apple\" , nb = 100 ) . value [ 'title' ] . to_list () classify = pyd . Daisi ( \"exampledaisies/Zero Shot Text Classification\" ) # Prepare a parallel execution dbe = classify . map ( func = \"compute\" , args_list = [{ \"text\" : title , \"candidate_labels\" : \"positive, negative\" } for title in news_title ]) dbe . start () # Wait for completion while \"RUNNING\" in dbe . value :","title":"A more realistic example"},{"location":"3.add-a-ui-streamlit/","text":"Add a UI to your Daisi \u00b6 Showcase the capabilities of your Daisies by giving them a front-end ! The Daisi platform currently supports Streamlit . More frameworks will be supported down the road. This is a great way to let your users test and understand what your Daisies can do. When you import streamlit in your code, the button Launch the app will be active in the Daisi page on app.daisi.io as well as the App button will be active on the Daisi card in the catalog. Any Streamlit app which runs in your local environment should run similarily when deployed on the Daisi platform. A good practice is to write the Streamlit commands inside a dedicated function and call this function in a if __name__ == \"__main__\" block, so it will not be imported when the Daisi is loaded for execution. If not, it will not prevent your Daisi to load and be executed, but it might make it slower. Example \u00b6 import streamlit as st def hello ( name = \"World\" ): return \"Hello \" + str ( name ) def st_ui (): name = st . text_input ( 'Type your name' ) st . header ( hello ( name )) if __name__ == \"__main__\" : st_ui () Turn this code into a daisi named Print Hello App by linking its Github repo in the Daisi platform. You have instantly an endpoint for the hello() function as well as a Streamlit app with a shareable URL. The Launch the app button is now active in the Daisi page, as well as the App button on this Daisi's card in the catalog (see image below). Check it out here : \"Print Hello App\" UI rendering \u00b6 Click on the Launch the App button. It will redirect you to a new browser tab displaying the app. Invokation \u00b6 Invoke the hello () endpoint with pydaisi : import pydaisi as pyd printhello = pyd . Daisi ( \"exampledaisies/Print Hello App\" ) print ( printhello . hello () . value ) Adding documentation inside the Streamlit app \u00b6 We strongly encourage Daisies creators to add a Markdown text in their Streamlit app wich reminds how to call the Daisi with a straight forward example, similar to what you could put in your DAISI.md readme. To keep the app clean, you can add the Markdown text inside an expander component, like this: import streamlit as st with st . expander ( \"Summary\" ): st . markdown ( '''A Markdown text explaining how to call the Daisi''' ) After adding a Markdown text, the Streamlit app for the above Daisi renders like this :","title":"Add a UI to your Daisi"},{"location":"3.add-a-ui-streamlit/#add-a-ui-to-your-daisi","text":"Showcase the capabilities of your Daisies by giving them a front-end ! The Daisi platform currently supports Streamlit . More frameworks will be supported down the road. This is a great way to let your users test and understand what your Daisies can do. When you import streamlit in your code, the button Launch the app will be active in the Daisi page on app.daisi.io as well as the App button will be active on the Daisi card in the catalog. Any Streamlit app which runs in your local environment should run similarily when deployed on the Daisi platform. A good practice is to write the Streamlit commands inside a dedicated function and call this function in a if __name__ == \"__main__\" block, so it will not be imported when the Daisi is loaded for execution. If not, it will not prevent your Daisi to load and be executed, but it might make it slower.","title":"Add a UI to your Daisi"},{"location":"3.add-a-ui-streamlit/#example","text":"import streamlit as st def hello ( name = \"World\" ): return \"Hello \" + str ( name ) def st_ui (): name = st . text_input ( 'Type your name' ) st . header ( hello ( name )) if __name__ == \"__main__\" : st_ui () Turn this code into a daisi named Print Hello App by linking its Github repo in the Daisi platform. You have instantly an endpoint for the hello() function as well as a Streamlit app with a shareable URL. The Launch the app button is now active in the Daisi page, as well as the App button on this Daisi's card in the catalog (see image below). Check it out here : \"Print Hello App\"","title":"Example"},{"location":"3.add-a-ui-streamlit/#ui-rendering","text":"Click on the Launch the App button. It will redirect you to a new browser tab displaying the app.","title":"UI rendering"},{"location":"3.add-a-ui-streamlit/#invokation","text":"Invoke the hello () endpoint with pydaisi : import pydaisi as pyd printhello = pyd . Daisi ( \"exampledaisies/Print Hello App\" ) print ( printhello . hello () . value )","title":"Invokation"},{"location":"3.add-a-ui-streamlit/#adding-documentation-inside-the-streamlit-app","text":"We strongly encourage Daisies creators to add a Markdown text in their Streamlit app wich reminds how to call the Daisi with a straight forward example, similar to what you could put in your DAISI.md readme. To keep the app clean, you can add the Markdown text inside an expander component, like this: import streamlit as st with st . expander ( \"Summary\" ): st . markdown ( '''A Markdown text explaining how to call the Daisi''' ) After adding a Markdown text, the Streamlit app for the above Daisi renders like this :","title":"Adding documentation inside the Streamlit app"},{"location":"4.sharing/","text":"Sharing Daisies - Teams \u00b6 When you create a new Daisi, it is by default private and visible only by yourself. No one else can discover it in the Daisi catalog, or invoke any of its endpoints, even if they would know how to call it. Following their creation, Daisies can be shared privately inside a team, or made public. If a Daisi is created from a private Github repository, it can be made public but the code will not be visible by anyone inside the Daisi plateform. Note You need to be authentified to call a private Daisi (see the Authentication section). Teams creation and management \u00b6 You can create teams in the Daisi plateform and add users : Click on your profile icon (top right corner) Click on My teams Create a new team, or add users in the teams that you manage Each team has a unique manager , who is the only one able to add / remove users. Visibility settings \u00b6 Visibility settings of a Daisi that you have created can be adjusted in the Settings tab of the Daisi page : You can share it within a team by typing in the named of the team. You can make it public by cliking on Make public . When clicking on Make Public , any user of the Daisi plateform can view and call this Daisi, even if they are not logged in or authentified. However, if this Daisi has been created from a private Gihub repository, the code will not be visible by anyone. Each team member can make her own private Daisies visible by the team. Each team member can also add any public Daisi to the team.","title":"Sharing Daisies - Teams"},{"location":"4.sharing/#sharing-daisies-teams","text":"When you create a new Daisi, it is by default private and visible only by yourself. No one else can discover it in the Daisi catalog, or invoke any of its endpoints, even if they would know how to call it. Following their creation, Daisies can be shared privately inside a team, or made public. If a Daisi is created from a private Github repository, it can be made public but the code will not be visible by anyone inside the Daisi plateform. Note You need to be authentified to call a private Daisi (see the Authentication section).","title":"Sharing Daisies - Teams"},{"location":"4.sharing/#teams-creation-and-management","text":"You can create teams in the Daisi plateform and add users : Click on your profile icon (top right corner) Click on My teams Create a new team, or add users in the teams that you manage Each team has a unique manager , who is the only one able to add / remove users.","title":"Teams creation and management"},{"location":"4.sharing/#visibility-settings","text":"Visibility settings of a Daisi that you have created can be adjusted in the Settings tab of the Daisi page : You can share it within a team by typing in the named of the team. You can make it public by cliking on Make public . When clicking on Make Public , any user of the Daisi plateform can view and call this Daisi, even if they are not logged in or authentified. However, if this Daisi has been created from a private Gihub repository, the code will not be visible by anyone. Each team member can make her own private Daisies visible by the team. Each team member can also add any public Daisi to the team.","title":"Visibility settings"},{"location":"5.daisies-remix/","text":"Remixing daisies \u00b6 We have seen how to call Daisies remotely in Python with pydaisi . Because Daisies are simply Python code, they can also call other Daisies. This allows to rework the output of a Daisi with an other one, build workflows, orchestrations, give a Streamlit UI to a Daisi that you like, and so much more ! Daisies which call other Daisies will feature a different icon on their card. A simple example \u00b6 The \"Ask Bert\" Daisi returns data in a JSON format, which needs to be parsed to extract the answer returned by the model. Let's build a new Daisi, which will call \"Ask Bert\", post process its data and return them in a different format. And we can also build a nicer UI for Bert in this new Daisi. The code of the new Daisi simply looks like : import pydaisi as pyd import streamlit as st # Call the \"Ask BERT\" Daisi ask_bert = pyd . Daisi ( \"exampledaisies/Ask BERT\" ) # get_answer() is an endpoint def get_answer ( context , query ): answer = ask_bert . compute ( query , context ) . value # Post process the \"Ask BERT\" Daisi return staight_answer = answer [ 0 ][ 'data' ][ 'answer' ] answer_proba = int ( 100 * float ( answer [ 0 ][ 'data' ][ 'score' ])) highlighted_answer = answer [ 1 ][ 'data' ] return staight_answer , highlighted_answer , answer_proba Check its code here : Awesome Bert ! We can also add a nice Streamlit UI with the following simple code : def st_ui (): st . set_page_config ( layout = \"wide\" ) st . title ( \"Awesome Bert\" ) context = st . sidebar . text_area ( \"Enter a context\" , value = \"The potato is a starchy vegetable.\" , height = 400 ) col1 , col2 = st . columns ( 2 ) with col1 : query = st . text_input ( \"Enter your question\" , value = \"What is a potato?\" ) staight_answer , \\ highlighted_answer , \\ answer_proba = get_answser ( context , query ) st . header ( \"Answer : \" + staight_answer ) st . subheader ( \"Answer confidence : \" + str ( answer_proba ) + \"%\" ) st . write ( \"And this is the answer in context :\" ) st . write ( highlighted_answer , unsafe_allow_html = True ) with open ( \"DAISI.md\" , \"r\" ) as f : summary = f . read () with st . expander ( \"Summary\" , expanded = True ): st . markdown ( summary ) with col2 : st . image ( 'Bert_smile.png' , width = 300 ) The app is immediately deployed, with its backend powered by the \"Ask BERT\" Daisi. Here below is how it renders :","title":"Remixing daisies"},{"location":"5.daisies-remix/#remixing-daisies","text":"We have seen how to call Daisies remotely in Python with pydaisi . Because Daisies are simply Python code, they can also call other Daisies. This allows to rework the output of a Daisi with an other one, build workflows, orchestrations, give a Streamlit UI to a Daisi that you like, and so much more ! Daisies which call other Daisies will feature a different icon on their card.","title":"Remixing daisies"},{"location":"5.daisies-remix/#a-simple-example","text":"The \"Ask Bert\" Daisi returns data in a JSON format, which needs to be parsed to extract the answer returned by the model. Let's build a new Daisi, which will call \"Ask Bert\", post process its data and return them in a different format. And we can also build a nicer UI for Bert in this new Daisi. The code of the new Daisi simply looks like : import pydaisi as pyd import streamlit as st # Call the \"Ask BERT\" Daisi ask_bert = pyd . Daisi ( \"exampledaisies/Ask BERT\" ) # get_answer() is an endpoint def get_answer ( context , query ): answer = ask_bert . compute ( query , context ) . value # Post process the \"Ask BERT\" Daisi return staight_answer = answer [ 0 ][ 'data' ][ 'answer' ] answer_proba = int ( 100 * float ( answer [ 0 ][ 'data' ][ 'score' ])) highlighted_answer = answer [ 1 ][ 'data' ] return staight_answer , highlighted_answer , answer_proba Check its code here : Awesome Bert ! We can also add a nice Streamlit UI with the following simple code : def st_ui (): st . set_page_config ( layout = \"wide\" ) st . title ( \"Awesome Bert\" ) context = st . sidebar . text_area ( \"Enter a context\" , value = \"The potato is a starchy vegetable.\" , height = 400 ) col1 , col2 = st . columns ( 2 ) with col1 : query = st . text_input ( \"Enter your question\" , value = \"What is a potato?\" ) staight_answer , \\ highlighted_answer , \\ answer_proba = get_answser ( context , query ) st . header ( \"Answer : \" + staight_answer ) st . subheader ( \"Answer confidence : \" + str ( answer_proba ) + \"%\" ) st . write ( \"And this is the answer in context :\" ) st . write ( highlighted_answer , unsafe_allow_html = True ) with open ( \"DAISI.md\" , \"r\" ) as f : summary = f . read () with st . expander ( \"Summary\" , expanded = True ): st . markdown ( summary ) with col2 : st . image ( 'Bert_smile.png' , width = 300 ) The app is immediately deployed, with its backend powered by the \"Ask BERT\" Daisi. Here below is how it renders :","title":"A simple example"},{"location":"6.good-practices/","text":"Good practices and tips \u00b6 Here below are some good practices to make sure that your Daisies perform at best: Testing and debugging \u00b6 The general rule is that your code should first work as expected in your workspace, before being pushed to the Daisi platform. Even if it calls / remixes other Daisies, you should be able to test it locally since you can invoke these Daisies from anywhere. If it has a Streamlit front end, you should be able to run it in your workspace with streamlit run <your Python script> before pushing it in the platform. If it connects to APIs, you should first test these connections in your workspace. If it doesn't work locally, there is no reason that it will perform better in the Daisi platform. Imports and global variables \u00b6 When a Daisi is started as a service for execution, the Daisi platform will load imports and global variables in memory for the lifespan of the service (10 minutes for now). So any loading or import wich can be time consuming (data import, a large ML model, etc...) should be done globally, so it will not be loaded at each execution. For instance, instead of doing this: from tensorflow import keras def predict ( input_data ): # The model is loaded inside a function, so it will be reloaded # at each execution of the predict() endpoint. my_ml_model = keras . models . load_model ( \"path to the model\" ) result = my_ml_model . predict ( input_data ) return result Do this: from tensorflow import keras # The model will be loaded when the service starts and will be kept in memory # for subsequent executions during the service lifespan (10 minutes). my_ml_model = keras . models . load_model ( \"path to the model\" ) def predict ( input_data ): result = my_ml_model . predict ( input_data ) return result Streamlit apps \u00b6 Similarly, if the Streamlit components are called in the main script and not in a function, these calls will be made each time the service load. They will be probably unconsequential but at the same time they are unecessary and can slow down the service start time. So it is a good practice to wrap all the Streamlit calls inside a function, and call this function in a if __name__ == \"__main__\" block. For instance, instead of doing this: import streamlit as st #There is a my_func() endpoint for this Daisi def my_func ( name = \"World): return f \"Hello { name } \" # These statments will be called when loading the service st . title ( \"My app\" ) name = st . text_input ( \"Enter your name\" ) st . write ( my_func ( name )) Do this: import streamlit as st def my_func ( name = \"World): return f \"Hello { name } \" #Streamlit calls inside a function def st_ui (): st . title ( \"My app\" ) st . text_input ( \"Enter your name\" ) st . write ( my_func ( param )) # This block is ignored when loading the service # but will be processed when launching the Streamlit app if __name__ == \"__main__\" : st_ui ()","title":"Good practices and tips"},{"location":"6.good-practices/#good-practices-and-tips","text":"Here below are some good practices to make sure that your Daisies perform at best:","title":"Good practices and tips"},{"location":"6.good-practices/#testing-and-debugging","text":"The general rule is that your code should first work as expected in your workspace, before being pushed to the Daisi platform. Even if it calls / remixes other Daisies, you should be able to test it locally since you can invoke these Daisies from anywhere. If it has a Streamlit front end, you should be able to run it in your workspace with streamlit run <your Python script> before pushing it in the platform. If it connects to APIs, you should first test these connections in your workspace. If it doesn't work locally, there is no reason that it will perform better in the Daisi platform.","title":"Testing and debugging"},{"location":"6.good-practices/#imports-and-global-variables","text":"When a Daisi is started as a service for execution, the Daisi platform will load imports and global variables in memory for the lifespan of the service (10 minutes for now). So any loading or import wich can be time consuming (data import, a large ML model, etc...) should be done globally, so it will not be loaded at each execution. For instance, instead of doing this: from tensorflow import keras def predict ( input_data ): # The model is loaded inside a function, so it will be reloaded # at each execution of the predict() endpoint. my_ml_model = keras . models . load_model ( \"path to the model\" ) result = my_ml_model . predict ( input_data ) return result Do this: from tensorflow import keras # The model will be loaded when the service starts and will be kept in memory # for subsequent executions during the service lifespan (10 minutes). my_ml_model = keras . models . load_model ( \"path to the model\" ) def predict ( input_data ): result = my_ml_model . predict ( input_data ) return result","title":"Imports and global variables"},{"location":"6.good-practices/#streamlit-apps","text":"Similarly, if the Streamlit components are called in the main script and not in a function, these calls will be made each time the service load. They will be probably unconsequential but at the same time they are unecessary and can slow down the service start time. So it is a good practice to wrap all the Streamlit calls inside a function, and call this function in a if __name__ == \"__main__\" block. For instance, instead of doing this: import streamlit as st #There is a my_func() endpoint for this Daisi def my_func ( name = \"World): return f \"Hello { name } \" # These statments will be called when loading the service st . title ( \"My app\" ) name = st . text_input ( \"Enter your name\" ) st . write ( my_func ( name )) Do this: import streamlit as st def my_func ( name = \"World): return f \"Hello { name } \" #Streamlit calls inside a function def st_ui (): st . title ( \"My app\" ) st . text_input ( \"Enter your name\" ) st . write ( my_func ( param )) # This block is ignored when loading the service # but will be processed when launching the Streamlit app if __name__ == \"__main__\" : st_ui ()","title":"Streamlit apps"},{"location":"7.shared-data/","text":"Data store \u00b6 The Daisi platform features a Data store. Currently, it is a public and shared drive. Support for private folders will be added later on. You can access the Shared Data folder by clicking on your user profile in the upper right corner. Note A personal access token is required for share data access from pydaisi import SharedDataClient sd = SharedDataClient () # load the root directory folder = sd . Folder ( \"/\" ) # create new folder relative to folder new_folder = folder . create ( \"new_folder\" ) # upload file sd . upload_file ( \"/shared data/folder/path\" , \"/local/file/path\" ) sd . put_object ( \"/shared data/folder/path\" , < object bytes > , \"file name\" ) # download file sd . download_file ( \"/shared data/file/path\" , \"/local/path\" ) obj = sd . download_fileobj ( \"/shared data/file/path\" ) # list contents folder = sd . Folder ( \"/shared data/folder/path\" ) for f in folder . list (): print ( f . name ) # delete a file file = sd . File ( \"/shared data/file/path\" ) file . delete () # delete a folder folder = sd . Folder ( \"/shared data/folder/path\" ) folder . delete ()","title":"Data store"},{"location":"7.shared-data/#data-store","text":"The Daisi platform features a Data store. Currently, it is a public and shared drive. Support for private folders will be added later on. You can access the Shared Data folder by clicking on your user profile in the upper right corner. Note A personal access token is required for share data access from pydaisi import SharedDataClient sd = SharedDataClient () # load the root directory folder = sd . Folder ( \"/\" ) # create new folder relative to folder new_folder = folder . create ( \"new_folder\" ) # upload file sd . upload_file ( \"/shared data/folder/path\" , \"/local/file/path\" ) sd . put_object ( \"/shared data/folder/path\" , < object bytes > , \"file name\" ) # download file sd . download_file ( \"/shared data/file/path\" , \"/local/path\" ) obj = sd . download_fileobj ( \"/shared data/file/path\" ) # list contents folder = sd . Folder ( \"/shared data/folder/path\" ) for f in folder . list (): print ( f . name ) # delete a file file = sd . File ( \"/shared data/file/path\" ) file . delete () # delete a folder folder = sd . Folder ( \"/shared data/folder/path\" ) folder . delete ()","title":"Data store"},{"location":"use-cases/0.ml-model/","text":"Deploy a ML model with Daisi \u00b6","title":"Deploy a ML model with Daisi"},{"location":"use-cases/0.ml-model/#deploy-a-ml-model-with-daisi","text":"","title":"Deploy a ML model with Daisi"},{"location":"use-cases/1.daisi-airflow/","text":"Automate tasks with Daisi and Airflow \u00b6","title":"Automate tasks with Daisi and Airflow"},{"location":"use-cases/1.daisi-airflow/#automate-tasks-with-daisi-and-airflow","text":"","title":"Automate tasks with Daisi and Airflow"}]}